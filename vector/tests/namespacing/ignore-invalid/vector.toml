# Set global options
data_dir = "/var/lib/vector"

# Sample the data to save on cost
[transforms.apache_sample]
  inputs       = ["apache_parser"]
  type         = "sample"
  rate         = 2                             # only keep 50% (1/`rate`)

# Send structured data to a cost-effective long-term storage
[sinks.s3_archives]
  inputs         = ["apache_parser"]           # don't sample for S3
  type           = "aws_s3"
  region         = "us-east-1"
  bucket         = "my-log-archives"
  key_prefix     = "date=%Y-%m-%d"             # daily partitions, hive friendly format
  compression    = "gzip"                      # compress final objects
  framing.method = "newline_delimited"         # new line delimited...
  encoding.codec = "json"                      # ..JSON
  [sinks.s3_archives.batch]
    max_bytes   = 10000000                     # 10mb uncompressed

[[tests]]
  name = "first"
  [tests.input]
    insert_at = "apache_parser"
    type = "log"
    [tests.input.log_fields]
      "message" = "foo"
  [[tests.outputs]]
    extract_from = "apache_parser"
